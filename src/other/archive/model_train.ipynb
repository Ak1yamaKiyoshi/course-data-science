{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7061001,"sourceType":"datasetVersion","datasetId":4064978}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install dependencies ","metadata":{}},{"cell_type":"code","source":"# install spacy\n#!pip install --upgrade spacy\n#!pip install spacy-transformers -q\n#!python -m spacy download en\n#!python -m spacy download en_core_web_lg\n#!python -m spacy download en_core_web_trf\n#!-m pip install --upgrade transformers\n#!python -m spacy download en_trf_bertbaseuncased_lg","metadata":{"_uuid":"d7c84ab5-5118-4f9a-b6bf-8b01cf40d172","_cell_guid":"c9340bdc-3878-4009-bc13-3fe42c3c693f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dependencies ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom spacy.training.example import Example\nimport spacy\nfrom spacy.tokens import Doc, Token\nfrom sklearn.model_selection import train_test_split\nimport random\nimport time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset ","metadata":{}},{"cell_type":"code","source":"data_path = '/content/dataset_medium.csv'\ndf = pd.read_csv(data_path, delimiter=\",\",  error_bad_lines=False )\nprint(df.sample(5))\ndf.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['word'] = df['word'].map(lambda x: x.lower())\nsentences = df.groupby(\"sentence#\")[\"word\"].apply(list).values\nlabels = df.groupby(by = 'sentence#')['label'].apply(list).values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(zip(sentences[0], labels[0]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup model ","metadata":{}},{"cell_type":"code","source":"nlp = spacy.blank('en')\n\nif 'ner' not in nlp.pipe_names:\n    ner = nlp.add_pipe('ner', last=True)\nelse:\n    ner = nlp.get_pipe('ner')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare train data","metadata":{}},{"cell_type":"code","source":"TRAIN_DATA = []\nfor sentence, label in zip(sentences, labels):\n    doc = nlp.make_doc(' '.join(sentence))\n    ents = [(word.idx, word.idx+len(word), lab) for word, lab in zip(doc, label) if lab != 'O']\n    example = Example.from_dict(doc, {\"entities\": ents})\n    TRAIN_DATA.append(example)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"optimizer = nlp.initialize()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 40\nsteps = 1\nBATCH_SIZE = 12\n\nfor itn in range(epochs):\n\n    random.shuffle(TRAIN_DATA)\n    losses = {}\n    step_start = time.time()\n    for i, batch in enumerate(spacy.util.minibatch(TRAIN_DATA, size=BATCH_SIZE)):\n        nlp.update(batch, sgd=optimizer, losses=losses)\n    step_end = time.time()\n    step = step_end - step_start\n    steps += step\n    avg_time_per_step = steps / (i+1)\n\n    print(f\"{itn:03d}/{epochs:03d}; step: {round(step, 1)}; loss: {losses}\")\n    if float(str(losses['ner'])) < 1.9:\n      break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save model ","metadata":{}},{"cell_type":"code","source":"import pickle\nwith open('/content/spacy_model.pkl', 'wb') as f:\n    pickle.dump(nlp, f)","metadata":{},"execution_count":null,"outputs":[]}]}